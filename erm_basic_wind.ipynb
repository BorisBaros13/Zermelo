{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05703be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "from matplotlib import animation\n",
    "from matplotlib.collections import LineCollection\n",
    "\n",
    "# Device setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.set_default_dtype(torch.float32)\n",
    "print(\"Running on:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d4bf90",
   "metadata": {},
   "source": [
    "### Generating Wind Samples\n",
    "\n",
    "We generate wind samples from an OU process. We want good variation in wind samples, so let's go with little mean-reversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c797c269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters and wind generator function\n",
    "n = 50\n",
    "T = 50\n",
    "L_x = 20\n",
    "theta = 0.1\n",
    "mu = 0\n",
    "wind_sigma = 0.05\n",
    "tau = torch.tensor(1, device = device)\n",
    "# we will discretise wind on a finer grid, then choose only the relevant points\n",
    "# assuming that the trajectory is discretised with time-step 1\n",
    "def wind_process(T, theta, mu, wind_sigma, n, tau):\n",
    "    num_to_sim = int(T / tau)\n",
    "    winds = torch.zeros(n, num_to_sim + 1, device = device)\n",
    "    winds[:, 0] = 0.5 * torch.rand(n , device = device) - 0.25 \n",
    "    for step in range(1, num_to_sim + 1):\n",
    "        dW = torch.randn(n , device = device)\n",
    "        winds[:, step] = winds[:, step - 1] +(mu - winds[:, step - 1]) * theta * tau + wind_sigma * torch.sqrt(tau) * dW\n",
    "    # only return winds for the integer time-steps\n",
    "    final_wind = winds[:, 1:][:, ::int(1 / tau)]\n",
    "    # add initial wind to the front\n",
    "    winds = torch.cat((winds[:, 0].view(n, 1), final_wind), dim = 1)\n",
    "    return winds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9fb037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the generator and visualise\n",
    "\n",
    "winds_tester = wind_process(T, theta, mu, wind_sigma, n, tau)\n",
    "plt.plot(winds_tester.T, linewidth = 0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d07dd7",
   "metadata": {},
   "source": [
    "### Define Neural Network Architecture\n",
    "\n",
    "Single-hidden layer neural network. Keep it standard for the ERM training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f797e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_dim, width, output_dim):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.hidden_layer = nn.Linear(input_dim, width)\n",
    "        # self.hidden_layer.bias.data.zero_()\n",
    "        # self.hidden_layer.bias.requires_grad = False\n",
    "        self.sigmoid = nn.Tanh()\n",
    "        self.output_layer = nn.Linear(width, output_dim)\n",
    "        # self.output_layer.bias.data.zero_()\n",
    "        # self.output_layer.bias.requires_grad = False\n",
    "        # self.width = width\n",
    "        \n",
    "    def forward(self, x):\n",
    "        hidden_activations = self.sigmoid(self.hidden_layer(x))\n",
    "        unscaled = self.output_layer(hidden_activations)\n",
    "        return unscaled# / self.width"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d14d50f",
   "metadata": {},
   "source": [
    "### Loss Functions, Trajectory Realisation, and Uncontrolled Visualisation\n",
    "\n",
    "We start without any regularisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b87b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost functions\n",
    "A = 2 # controls how soft/hard the obstacle cost is\n",
    "M = 10 # controls how high the cost is\n",
    "def running_cost(x, y, A, M):\n",
    "    return( 1 - 1/(1 + torch.exp(A * (1 - x**2 - y**2)))) * M\n",
    "\n",
    "def terminal_cost(x, y, L_x):\n",
    "    return torch.norm(x - L_x, dim = 1, keepdim = True)**2 + torch.norm(y, dim = 1, keepdim = True)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a214a69a",
   "metadata": {},
   "source": [
    "Before any training, we must produce our reference-controlled paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99424be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_ctrl = torch.zeros(n, 1, device = device)\n",
    "initial_points = torch.zeros(n, 2, device = device) - torch.tensor([20, 0], device = device)\n",
    "training_winds = wind_process(T, theta, mu, wind_sigma, n, tau)\n",
    "def gen_ref_path(reference_control, p0, winds, vs, T, n):\n",
    "    ref_path = torch.zeros(n, T+1, 2, device = device) # use a 3D tensor to store path information\n",
    "    ref_path[:, 0, :] = p0 \n",
    "    for t in range(T): \n",
    "        heading = torch.cat([torch.cos(reference_control), torch.sin(reference_control)], dim = 1)\n",
    "        wind_vec = torch.cat([torch.zeros(n, device = device).view(n, 1), winds[:, t].view(n, 1)], dim = 1)\n",
    "        ref_path[:, t+1, :] = ref_path[:, t] + vs * heading + wind_vec\n",
    "    return ref_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf81286",
   "metadata": {},
   "outputs": [],
   "source": [
    "tester = gen_ref_path(ref_ctrl, initial_points, training_winds, 0.8, T, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce631744",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pth in range(tester.shape[0]):\n",
    "    plt.plot(tester[pth, :, 0], tester[pth, :, 1], linewidth = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60895e30",
   "metadata": {},
   "source": [
    "Our training procedure is as follows:\n",
    "1. Parallelising over all steps in the backwards induction and training simultaneously. \n",
    "2. Run the forward pass from time t to T via the chosen models.\n",
    "3. Compute the losses in a vectorised manner on the realised trajectories (more efficient than interchanging 2 and 3 at each step)\n",
    "4. Backpropagate over model t.\n",
    "\n",
    "We will begin with the unregularised version, and will start without parallelising over all t."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79449f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise models, optimisers and learning rates\n",
    "input_dim, width, output_dim = 3, 1000, 1\n",
    "start_rate, final_rate, num_epochs = 0.1, 0.00001, 1\n",
    "models = [NeuralNet(input_dim, width, output_dim).to(device) for _ in range(T)]\n",
    "optimizers = [optim.AdamW(model.parameters(), lr=start_rate) for model in models]\n",
    "schedulers = [optim.lr_scheduler.CosineAnnealingLR(opt, T_max = num_epochs, eta_min = final_rate) for opt in optimizers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4058a413",
   "metadata": {},
   "outputs": [],
   "source": [
    "vs = 0.8\n",
    "ref_path = gen_ref_path(ref_ctrl, initial_points, training_winds, vs, T, n)\n",
    "training_winds = wind_process(T, theta, mu, wind_sigma, n, tau)\n",
    "\n",
    "# run without training first, just to check correctness of computation\n",
    "for t in reversed(range(T)):\n",
    "    print(f\"Backwards Inductive Step t = {t}...\")\n",
    "    path_length = T - t\n",
    "    for epoch in range(num_epochs):\n",
    "        current_paths = torch.zeros(n, path_length + 1, 2, device = device) # + 1 since we store X_t^{ref}(Z) too\n",
    "        current_paths[:, 0, :] = ref_path[:, t, :]\n",
    "        # generate path from T\n",
    "        for futs in range(path_length):\n",
    "            angle = models[t + futs](torch.cat([current_paths[:, futs, :], training_winds[:, t + futs].view(n, 1)], dim = 1))\n",
    "            heading = torch.cat([torch.cos(angle), torch.sin(angle)], dim = 1)\n",
    "            wind_vec = torch.cat([torch.zeros(n, device = device).view(n, 1), training_winds[:, t + futs].view(n, 1)], dim = 1)\n",
    "            current_paths[:, futs + 1, :] = current_paths[:, futs, :] + vs * heading + wind_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a86d566",
   "metadata": {},
   "source": [
    "Visualising the obstacle cost over the different sample paths below. Use this to tinker with our choices for A and M. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173c6e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "costs = running_cost(current_paths[:, :, 0], current_paths[:, :, 1], 0.5, 100)\n",
    "import seaborn as sns\n",
    "sns.heatmap(costs.detach())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da037dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's train\n",
    "models = [NeuralNet(input_dim, width, output_dim).to(device) for _ in range(T)]\n",
    "optimizers = [optim.AdamW(model.parameters(), lr=start_rate) for model in models]\n",
    "schedulers = [optim.lr_scheduler.CosineAnnealingLR(opt, T_max = num_epochs, eta_min = final_rate) for opt in optimizers]\n",
    "input_dim, width, output_dim = 3, 1000, 1\n",
    "start_rate, final_rate, num_epochs = 0.00001, 0.000000001, 3000\n",
    "vs = 0.8\n",
    "n = 60\n",
    "A = 2\n",
    "M = 1\n",
    "ref_ctrl = torch.zeros(n, 1, device = device)\n",
    "initial_points = torch.zeros(n, 2, device = device) - torch.tensor([20, 0], device = device)\n",
    "training_winds = wind_process(T, theta, mu, wind_sigma, n, tau)\n",
    "ref_path = gen_ref_path(ref_ctrl, initial_points, training_winds, vs, T, n)\n",
    "# zeros and ones vectors so we don't keep having to remake it\n",
    "zeros_vec, ones_vec = torch.zeros(n, 1, device = device), torch.ones(n, 1, device = device)\n",
    "# run without training first, just to check correctness of computation\n",
    "for t in reversed(range(T)):\n",
    "    print(f\"Backwards Inductive Step t = {t}...\")\n",
    "    path_length = T - t\n",
    "    for epoch in range(num_epochs):\n",
    "        final_c = 0\n",
    "        current_paths = [ref_path[:, t, :]]\n",
    "        # generate path from T\n",
    "        for futs in range(path_length):\n",
    "            angle = models[t + futs](torch.cat([current_paths[-1]/torch.tensor([20, 10]), training_winds[:, t + futs].view(n, 1)], dim = 1))\n",
    "            heading = torch.cat([torch.cos(angle), torch.sin(angle)], dim = 1)\n",
    "            wind_vec = torch.cat([zeros_vec, training_winds[:, t + futs].view(n, 1)], dim = 1)\n",
    "            new_p = current_paths[-1] + vs * heading + wind_vec\n",
    "            current_paths.append(new_p)\n",
    "        # stack current_paths into a 3D tensor\n",
    "        current_paths = torch.stack(current_paths, dim = 1)\n",
    "        # compute losses\n",
    "        # for running cost, exclude initial point (uncontrolled)\n",
    "        running_c = running_cost(current_paths[:, 1:, 0], current_paths[:, 1:, 1], 2, 100)\n",
    "        running_c = torch.sum(running_c, dim = 1)\n",
    "        terminal_c = terminal_cost(current_paths[:, -1, 0].view(n, 1), current_paths[:, -1, 1].view(n ,1), L_x).view(n, 1)\n",
    "        final_c = torch.mean(running_c + terminal_c)\n",
    "        # backprop and update\n",
    "        final_c.backward()\n",
    "        optimizers[t].step()\n",
    "        optimizers[t].zero_grad()\n",
    "        schedulers[t].step()\n",
    "\n",
    "        if epoch % 1000 == 0:\n",
    "            with torch.no_grad():\n",
    "                print(f\" Epoch: {epoch}, Obstacle Cost: {running_c.mean().item():.6f}, Terminal Cost: {terminal_c.mean().item():.6f}\")\n",
    "    # freeze model after training\n",
    "    for param in models[t].parameters():\n",
    "        param.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20d846b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pth in range(n):\n",
    "    plt.plot(current_paths[pth, :, 0].cpu().detach(), current_paths[pth, :, 1].cpu().detach(), linewidth = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbaafce",
   "metadata": {},
   "outputs": [],
   "source": [
    "how_many = 10\n",
    "for pth in range(how_many):\n",
    "    plt.plot(final_angles[pth].cpu().detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692915c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pth in range(how_many):\n",
    "    plt.plot(training_winds[pth,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208ecaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_control = torch.zeros(n, 1, device=device)\n",
    "ref_path = [initial_points.to(device)] \n",
    "\n",
    "for pos in range(T):\n",
    "    wind_y = training_winds[:, pos].view(n, 1).to(device)\n",
    "    wind_vector = torch.cat([torch.zeros_like(wind_y), wind_y], dim=1)\n",
    "    heading = torch.cat([torch.cos(ref_control), torch.sin(ref_control)], dim=1)\n",
    "    velocity = vs * heading +  wind_vector\n",
    "    new_p = ref_path[-1] + velocity\n",
    "    ref_path.append(new_p)\n",
    "\n",
    "# Backward rollout\n",
    "anim_paths = {}\n",
    "wind_values = {}\n",
    "\n",
    "anim_paths[f\"{T}\"] = ref_path\n",
    "for t in range(T - 1, -1, -1):\n",
    "    curr_path = ref_path[:t + 1]\n",
    "    # curr_wind = [training_data[:, :t + 1]]\n",
    "    curr_wind = [training_winds[:, i].view(n, 1) for i in range(t + 1)]\n",
    "\n",
    "    curr_p = curr_path[-1]\n",
    "    for rem in range(0, T - t):\n",
    "        wind_val = training_winds[:, t + rem].view(n, 1).to(device)\n",
    "        wind_vector = torch.cat([torch.zeros_like(wind_val), wind_val], dim=1)\n",
    "        input_tensor = torch.cat((curr_p/torch.tensor([20, 10]), wind_val), dim=1)\n",
    "\n",
    "        curr_control = models[t + rem](input_tensor)\n",
    "        heading = torch.cat([torch.cos(curr_control), torch.sin(curr_control)], dim=1)\n",
    "        velocity = vs * heading + wind_vector\n",
    "        curr_p = curr_p + velocity\n",
    "\n",
    "        curr_path.append(curr_p)\n",
    "        curr_wind.append(wind_val)\n",
    "\n",
    "    anim_paths[f\"{t}\"] = curr_path\n",
    "    wind_values[f\"{t}\"] = curr_wind\n",
    "\n",
    "# Prepare data for animation\n",
    "plt.rcParams['animation.embed_limit'] = 100  # (in MB, e.g., 100 MB)\n",
    "frame_data = []\n",
    "for key in sorted(anim_paths.keys(), key=lambda k: int(k)):\n",
    "    step_list = anim_paths[key]\n",
    "    wind_list = wind_values.get(key, [])\n",
    "    positions = torch.stack(step_list, dim=0).detach().cpu()  # (steps, N, 2)\n",
    "    wind_vals = torch.stack(wind_list, dim=0).squeeze(-1).detach().cpu() if wind_list else None  # (steps, N)\n",
    "    frame_data.append((int(key), positions, wind_vals))\n",
    "frame_data.reverse()\n",
    "\n",
    "# Setup plot\n",
    "L_x, L_y = 20, 6\n",
    "num_paths_to_show = n\n",
    "interval = 100\n",
    "\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"axes.titlesize\": 30,\n",
    "    \"axes.labelsize\": 30,\n",
    "    \"xtick.labelsize\": 25,\n",
    "    \"ytick.labelsize\": 25,\n",
    "    \"legend.fontsize\": 25,\n",
    "    \"font.size\": 25\n",
    "})\n",
    "fig, ax = plt.subplots(figsize=(19.2, 10.8), constrained_layout=True)\n",
    "ax.set_xlim(-L_x, L_x)\n",
    "ax.set_ylim(-L_y, L_y)\n",
    "ax.plot(20, 0, 'ko', markersize=20, zorder=1000)\n",
    "\n",
    "# Obstacle contour\n",
    "grid_res = 300\n",
    "x_vals = torch.linspace(-6, 6, grid_res)\n",
    "y_vals = torch.linspace(-6, 6, grid_res)\n",
    "X, Y = torch.meshgrid(x_vals, y_vals, indexing='xy')\n",
    "Z = running_cost(X, Y, A=2, M=10) * 100\n",
    "Z[Z < 1.5] = float('nan')\n",
    "ax.contourf(X.numpy(), Y.numpy(), Z.numpy(), levels=10, cmap='Greys', alpha=0.8)\n",
    "\n",
    "# Plot elements\n",
    "grey_lines = [ax.plot([], [], linestyle='--', color='grey', lw=1)[0] for _ in range(num_paths_to_show)]\n",
    "collections = []\n",
    "# Plotting parameters\n",
    "\n",
    "norm = plt.Normalize(training_winds.min().item(), training_winds.max().item())\n",
    "cmap = plt.cm.plasma\n",
    "sm = plt.cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "cbar = plt.colorbar(sm, ax=ax)\n",
    "cbar.set_label(\"Wind Value\")\n",
    "\n",
    "# --- Animation functions ---\n",
    "def init():\n",
    "    for line in grey_lines:\n",
    "        line.set_data([], [])\n",
    "    for coll in collections:\n",
    "        coll.remove()\n",
    "    collections.clear()\n",
    "    return grey_lines\n",
    "\n",
    "def update(frame_idx):\n",
    "    for coll in collections:\n",
    "        coll.remove()\n",
    "    collections.clear()\n",
    "\n",
    "    epoch_idx, data, winds = frame_data[frame_idx]\n",
    "    ax.set_title(f\"Backward Inductive Step = {epoch_idx}\")\n",
    "\n",
    "    for i in range(num_paths_to_show):\n",
    "        if i >= data.shape[1]:\n",
    "            continue\n",
    "        x = data[:, i, 0].numpy()\n",
    "        y = data[:, i, 1].numpy()\n",
    "\n",
    "        # Grey past\n",
    "        grey_lines[i].set_data(x[:epoch_idx + 1], y[:epoch_idx + 1])\n",
    "\n",
    "        # Color future\n",
    "        if winds is not None and epoch_idx < data.shape[0] - 1:\n",
    "            segments = np.stack([x[epoch_idx:], y[epoch_idx:]], axis=-1)\n",
    "            points = segments[:-1]\n",
    "            segs = np.stack([points, segments[1:]], axis=1)\n",
    "            colors = cmap(norm(winds[epoch_idx + 1:, i].numpy()))\n",
    "\n",
    "            lc = LineCollection(segs, colors=colors, linewidths=2)\n",
    "            ax.add_collection(lc)\n",
    "            collections.append(lc)\n",
    "\n",
    "    return grey_lines + collections\n",
    "\n",
    "ani = animation.FuncAnimation(\n",
    "    fig, update, frames=len(frame_data),\n",
    "    init_func=init, blit=False, interval=interval\n",
    ")\n",
    "\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fbc37a",
   "metadata": {},
   "source": [
    "### Testing Phase\n",
    "\n",
    "Ideally, we should see pretty poor behaviour out-of-sample, as our models overlearn on the given training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300596bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 500\n",
    "test_winds = wind_process(T, theta, mu, wind_sigma, test_size, tau)\n",
    "test_initial_points = torch.zeros(test_size, 2, device = device) - torch.tensor([20, 0], device = device)\n",
    "test_paths = [test_initial_points]\n",
    "zeros_vec = torch.zeros(test_size, 1, device = device)\n",
    "# forward rollout\n",
    "for t in range(T):\n",
    "    wind_vec = torch.cat([zeros_vec,\n",
    "                          test_winds[:, t].view(test_size, 1)], dim = 1)\n",
    "    angle = models[t](torch.cat([test_paths[-1]/torch.tensor([20, 10]),\n",
    "                                test_winds[:, t].view(test_size, 1)], dim = 1))\n",
    "    heading = torch.cat([torch.cos(angle), torch.sin(angle)], dim = 1)\n",
    "    new_p = test_paths[-1] + vs * heading + wind_vec\n",
    "    test_paths.append(new_p)\n",
    "test_paths = torch.stack(test_paths, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631f2917",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pth in range(test_size):\n",
    "    plt.plot(test_paths[pth, :, 0].cpu().detach(), test_paths[pth, :, 1].cpu().detach(), linewidth = 0.5, alpha = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9aef05b",
   "metadata": {},
   "source": [
    "We try everything again, this time using a deeper neural network. This may make feature learning easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077136fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet_2(nn.Module):\n",
    "    def __init__(self, input_dim, width, output_dim):\n",
    "        super(NeuralNet_2, self).__init__()\n",
    "        self.hidden_layer = nn.Linear(input_dim, width)\n",
    "        self.hidden_layer_2 = nn.Linear(width, width)\n",
    "        self.hidden_layer_3 = nn.Linear(width, width)\n",
    "        self.sigmoid = nn.Tanh()\n",
    "        self.output_layer = nn.Linear(width, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        activations_1 = self.sigmoid(self.hidden_layer(x))\n",
    "        activations_2 = self.sigmoid(self.hidden_layer_2(activations_1))\n",
    "        activations_3 = self.sigmoid(self.hidden_layer_3(activations_2))\n",
    "        unscaled = self.output_layer(activations_2)\n",
    "        return unscaled# / self.width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddf4ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's train\n",
    "input_dim, width, output_dim = 3, 200, 1\n",
    "start_rate, final_rate, num_epochs = 0.001, 0.000000001, 3000\n",
    "models_2 = [NeuralNet_2(input_dim, width, output_dim).to(device) for _ in range(T)]\n",
    "optimizers_2 = [optim.AdamW(model.parameters(), lr=start_rate) for model in models_2]\n",
    "schedulers_2 = [optim.lr_scheduler.CosineAnnealingLR(opt, T_max = num_epochs, eta_min = final_rate) for opt in optimizers_2]\n",
    "\n",
    "vs = 0.8\n",
    "n = 60\n",
    "A = 2\n",
    "M = 10\n",
    "ref_ctrl = torch.zeros(n, 1, device = device)\n",
    "initial_points = torch.zeros(n, 2, device = device) - torch.tensor([20, 0], device = device)\n",
    "training_winds = wind_process(T, theta, mu, wind_sigma, n, tau)\n",
    "ref_path_2 = gen_ref_path(ref_ctrl, initial_points, training_winds, vs, T, n)\n",
    "# zeros and ones vectors so we don't keep having to remake it\n",
    "zeros_vec, ones_vec = torch.zeros(n, 1, device = device), torch.ones(n, 1, device = device)\n",
    "# run without training first, just to check correctness of computation\n",
    "for t in reversed(range(T)):\n",
    "    print(f\"Backwards Inductive Step t = {t}...\")\n",
    "    path_length = T - t\n",
    "    for epoch in range(num_epochs):\n",
    "        final_c = 0\n",
    "        current_paths_2 = [ref_path_2[:, t, :]]\n",
    "        # generate path from T\n",
    "        for futs in range(path_length):\n",
    "            angle = models_2[t + futs](torch.cat([current_paths_2[-1]/torch.tensor([20, 10]),\n",
    "                                                   training_winds[:, t + futs].view(n, 1)], dim = 1))\n",
    "            heading = torch.cat([torch.cos(angle),\n",
    "                                  torch.sin(angle)], dim = 1)\n",
    "            wind_vec = torch.cat([zeros_vec,\n",
    "                                   training_winds[:, t + futs].view(n, 1)], dim = 1)\n",
    "            new_p = current_paths_2[-1] + vs * heading + wind_vec\n",
    "            current_paths_2.append(new_p)\n",
    "        # stack current_paths into a 3D tensor\n",
    "        current_paths_2 = torch.stack(current_paths_2, dim = 1)\n",
    "        # compute losses\n",
    "        # for running cost, exclude initial point (uncontrolled)\n",
    "        running_c = running_cost(current_paths_2[:, 1:, 0], current_paths_2[:, 1:, 1], A, M)\n",
    "        running_c = torch.sum(running_c, dim = 1)\n",
    "        terminal_c = terminal_cost(current_paths_2[:, -1, 0].view(n, 1), current_paths_2[:, -1, 1].view(n ,1), L_x).view(n, 1)\n",
    "        final_c = torch.mean(running_c + terminal_c)\n",
    "        # backprop and update\n",
    "        final_c.backward()\n",
    "        optimizers_2[t].step()\n",
    "        optimizers_2[t].zero_grad()\n",
    "        schedulers_2[t].step()\n",
    "\n",
    "        if epoch % 1000 == 0:\n",
    "            with torch.no_grad():\n",
    "                print(f\" Epoch: {epoch}, Obstacle Cost: {running_c.mean().item():.6f}, Terminal Cost: {terminal_c.mean().item():.6f}\")\n",
    "    # freeze model after training\n",
    "    for param in models_2[t].parameters():\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4bd48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pth in range(n):\n",
    "    plt.plot(current_paths_2[pth, :, 0].cpu().detach(), current_paths_2[pth, :, 1].cpu().detach(), linewidth = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf53bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_control = torch.zeros(n, 1, device=device)\n",
    "ref_path = [initial_points.to(device)] \n",
    "\n",
    "for pos in range(T):\n",
    "    wind_y = training_winds[:, pos].view(n, 1).to(device)\n",
    "    wind_vector = torch.cat([torch.zeros_like(wind_y), wind_y], dim=1)\n",
    "    heading = torch.cat([torch.cos(ref_control), torch.sin(ref_control)], dim=1)\n",
    "    velocity = vs * heading +  wind_vector\n",
    "    new_p = ref_path[-1] + velocity\n",
    "    ref_path.append(new_p)\n",
    "\n",
    "# Backward rollout\n",
    "anim_paths = {}\n",
    "wind_values = {}\n",
    "\n",
    "anim_paths[f\"{T}\"] = ref_path\n",
    "for t in range(T - 1, -1, -1):\n",
    "    curr_path = ref_path[:t + 1]\n",
    "    # curr_wind = [training_data[:, :t + 1]]\n",
    "    curr_wind = [training_winds[:, i].view(n, 1) for i in range(t + 1)]\n",
    "\n",
    "    curr_p = curr_path[-1]\n",
    "    for rem in range(0, T - t):\n",
    "        wind_val = training_winds[:, t + rem].view(n, 1).to(device)\n",
    "        wind_vector = torch.cat([torch.zeros_like(wind_val), wind_val], dim=1)\n",
    "        input_tensor = torch.cat((curr_p/torch.tensor([20, 10]), wind_val), dim=1)\n",
    "\n",
    "        curr_control = models_2[t + rem](input_tensor)\n",
    "        heading = torch.cat([torch.cos(curr_control), torch.sin(curr_control)], dim=1)\n",
    "        velocity = vs * heading + wind_vector\n",
    "        curr_p = curr_p + velocity\n",
    "\n",
    "        curr_path.append(curr_p)\n",
    "        curr_wind.append(wind_val)\n",
    "\n",
    "    anim_paths[f\"{t}\"] = curr_path\n",
    "    wind_values[f\"{t}\"] = curr_wind\n",
    "\n",
    "# Prepare data for animation\n",
    "plt.rcParams['animation.embed_limit'] = 100  # (in MB, e.g., 100 MB)\n",
    "frame_data = []\n",
    "for key in sorted(anim_paths.keys(), key=lambda k: int(k)):\n",
    "    step_list = anim_paths[key]\n",
    "    wind_list = wind_values.get(key, [])\n",
    "    positions = torch.stack(step_list, dim=0).detach().cpu()  # (steps, N, 2)\n",
    "    wind_vals = torch.stack(wind_list, dim=0).squeeze(-1).detach().cpu() if wind_list else None  # (steps, N)\n",
    "    frame_data.append((int(key), positions, wind_vals))\n",
    "frame_data.reverse()\n",
    "\n",
    "# Setup plot\n",
    "L_x, L_y = 20, 6\n",
    "num_paths_to_show = n\n",
    "interval = 100\n",
    "\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"axes.titlesize\": 30,\n",
    "    \"axes.labelsize\": 30,\n",
    "    \"xtick.labelsize\": 25,\n",
    "    \"ytick.labelsize\": 25,\n",
    "    \"legend.fontsize\": 25,\n",
    "    \"font.size\": 25\n",
    "})\n",
    "fig, ax = plt.subplots(figsize=(19.2, 10.8), constrained_layout=True)\n",
    "ax.set_xlim(-L_x, L_x)\n",
    "ax.set_ylim(-L_y, L_y)\n",
    "ax.plot(20, 0, 'ko', markersize=20, zorder=1000)\n",
    "\n",
    "# Obstacle contour\n",
    "grid_res = 300\n",
    "x_vals = torch.linspace(-6, 6, grid_res)\n",
    "y_vals = torch.linspace(-6, 6, grid_res)\n",
    "X, Y = torch.meshgrid(x_vals, y_vals, indexing='xy')\n",
    "Z = running_cost(X, Y, A=2, M=10) * 100\n",
    "Z[Z < 1.5] = float('nan')\n",
    "ax.contourf(X.numpy(), Y.numpy(), Z.numpy(), levels=10, cmap='Greys', alpha=0.8)\n",
    "\n",
    "# Plot elements\n",
    "grey_lines = [ax.plot([], [], linestyle='--', color='grey', lw=1)[0] for _ in range(num_paths_to_show)]\n",
    "collections = []\n",
    "# Plotting parameters\n",
    "\n",
    "norm = plt.Normalize(training_winds.min().item(), training_winds.max().item())\n",
    "cmap = plt.cm.plasma\n",
    "sm = plt.cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "cbar = plt.colorbar(sm, ax=ax)\n",
    "cbar.set_label(\"Wind Value\")\n",
    "\n",
    "# --- Animation functions ---\n",
    "def init():\n",
    "    for line in grey_lines:\n",
    "        line.set_data([], [])\n",
    "    for coll in collections:\n",
    "        coll.remove()\n",
    "    collections.clear()\n",
    "    return grey_lines\n",
    "\n",
    "def update(frame_idx):\n",
    "    for coll in collections:\n",
    "        coll.remove()\n",
    "    collections.clear()\n",
    "\n",
    "    epoch_idx, data, winds = frame_data[frame_idx]\n",
    "    ax.set_title(f\"Backward Inductive Step = {epoch_idx}\")\n",
    "\n",
    "    for i in range(num_paths_to_show):\n",
    "        if i >= data.shape[1]:\n",
    "            continue\n",
    "        x = data[:, i, 0].numpy()\n",
    "        y = data[:, i, 1].numpy()\n",
    "\n",
    "        # Grey past\n",
    "        grey_lines[i].set_data(x[:epoch_idx + 1], y[:epoch_idx + 1])\n",
    "\n",
    "        # Color future\n",
    "        if winds is not None and epoch_idx < data.shape[0] - 1:\n",
    "            segments = np.stack([x[epoch_idx:], y[epoch_idx:]], axis=-1)\n",
    "            points = segments[:-1]\n",
    "            segs = np.stack([points, segments[1:]], axis=1)\n",
    "            colors = cmap(norm(winds[epoch_idx + 1:, i].numpy()))\n",
    "\n",
    "            lc = LineCollection(segs, colors=colors, linewidths=2)\n",
    "            ax.add_collection(lc)\n",
    "            collections.append(lc)\n",
    "\n",
    "    return grey_lines + collections\n",
    "\n",
    "ani = animation.FuncAnimation(\n",
    "    fig, update, frames=len(frame_data),\n",
    "    init_func=init, blit=False, interval=interval\n",
    ")\n",
    "\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fdff1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 500\n",
    "test_winds = wind_process(T, theta, mu, wind_sigma, test_size, tau)\n",
    "test_initial_points = torch.zeros(test_size, 2, device = device) - torch.tensor([20, 0], device = device)\n",
    "test_paths = [test_initial_points]\n",
    "zeros_vec = torch.zeros(test_size, 1, device = device)\n",
    "# forward rollout\n",
    "for t in range(T):\n",
    "    wind_vec = torch.cat([zeros_vec,\n",
    "                          test_winds[:, t].view(test_size, 1)], dim = 1)\n",
    "    angle = models_2[t](torch.cat([test_paths[-1]/torch.tensor([20, 10]),\n",
    "                                test_winds[:, t].view(test_size, 1)], dim = 1))\n",
    "    heading = torch.cat([torch.cos(angle), torch.sin(angle)], dim = 1)\n",
    "    new_p = test_paths[-1] + vs * heading + wind_vec\n",
    "    test_paths.append(new_p)\n",
    "test_paths = torch.stack(test_paths, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2b8274",
   "metadata": {},
   "outputs": [],
   "source": [
    "how_many = 10\n",
    "for pth in range(how_many):\n",
    "    plt.plot(test_paths[pth, :, 0].cpu().detach(),\n",
    "             test_paths[pth, :, 1].cpu().detach(), linewidth = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e45aae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
